{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "# Anvendt Programmering 5\n",
    "---\n",
    "## Machine Learning Basics with Scikit-Learn and Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d89c45d",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction\n",
    "\n",
    "- Welcome to the lecture on Machine Learning Basics with Scikit-Learn and Python.\n",
    "- Objectives:\n",
    "  - Understand basic machine learning concepts\n",
    "  - Learn how to use scikit-learn for machine learning tasks\n",
    "  - Complete two hands-on exercises\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b76cb",
   "metadata": {},
   "source": [
    "\n",
    "# Setting Up Your Environment\n",
    "\n",
    "- Install packages using pip:\n",
    "\n",
    "```bash\n",
    "pip install jupyter\n",
    "pip install scikit-learn\n",
    "pip install matplotlib\n",
    "pip install seaborn\n",
    "pip install pandas\n",
    "pip install seaborn\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97068c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn matplotlib seaborn pandas jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46574860",
   "metadata": {},
   "source": [
    "\n",
    "# Understanding the Basics\n",
    "\n",
    "- **Supervised Learning**: Training a model on labeled data (e.g., classification, regression).\n",
    "- **Unsupervised Learning**: Training a model on unlabeled data (e.g., clustering, dimensionality reduction).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f3c7b",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "\n",
    "A type of machine learning where the algorithm learns patterns from unlabeled data.\n",
    "- **Key Methods**:\n",
    "  - Clustering\n",
    "  - Dimensionality Reduction\n",
    "- **Applications**:\n",
    "  - Customer segmentation\n",
    "  - Anomaly detection\n",
    "  - Image compression\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a0573d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is K-means Clustering?\n",
    "\n",
    "- **K-means Clustering**: A method to partition data into K clusters, where each data point belongs to the cluster with the nearest mean.\n",
    "- **Steps**:\n",
    "  1. Initialize K centroids randomly.\n",
    "  2. Assign each data point to the nearest centroid.\n",
    "  3. Update centroids by calculating the mean of assigned points.\n",
    "  4. Repeat steps 2-3 until convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc8aa88",
   "metadata": {},
   "source": [
    "# Visualizing K-means Clustering\n",
    "\n",
    "- Data points grouped into 4 clusters.\n",
    "- Feature is just a measurement of a specific sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987bcc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "N_CLUSTERS = 2\n",
    "# Generate sample data\n",
    "X, _ = make_blobs(n_samples=300, centers=N_CLUSTERS, cluster_std=0.60, random_state=0)\n",
    "df = pd.DataFrame(X, columns=[\"x\", \"y\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb728a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the data\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.title(\"Scatter Plot for Unlabelled data\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e87c7b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## K-means Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7de3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)\n",
    "\n",
    "# Visualization of the Clusters\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap=\"viridis\")\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c=\"red\", s=200, alpha=0.75)\n",
    "plt.title(\"Scatter Plot for K-means Clustering\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54f9c8f",
   "metadata": {},
   "source": [
    "# KMeans on breastcancer patients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2be5c6",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04d169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "\n",
    "# Display the dataframe\n",
    "df_all = pd.DataFrame(X, columns=data.feature_names)\n",
    "\n",
    "df_all[\"Target\"] = y\n",
    "df_all[\"Target\"] = df_all[\"Target\"].map({i: v for i, v in enumerate(data.target_names)})\n",
    "df_all.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e363886",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Splitting Data into training and test datasets\n",
    "\n",
    "- Splitting data into training and testing sets helps evaluate the model's performance on unseen data, ensuring it generalizes well.\n",
    "\n",
    "- Data can be split into Training, Test, Validation\n",
    "- Generally a good split is:\n",
    "    - Training:80\\%\n",
    "    - Test 20\\% \n",
    "    - At some point you will also get to worry about validation, however, we will skip this for now!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8339baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# Normalize X\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Display the dataframe\n",
    "df_test = pd.DataFrame(X_test, columns=data.feature_names)\n",
    "\n",
    "df_test[\"Target\"] = y_test\n",
    "df_test[\"Target\"] = df_test[\"Target\"].map({i: v for i, v in enumerate(data.target_names)})\n",
    "\n",
    "df_test.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a195455",
   "metadata": {},
   "source": [
    "## Visualize Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24f6135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df_all, hue=\"Target\", vars=data.feature_names[:3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628ebdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df_test, hue=\"Target\", vars=data.feature_names[:3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c430a0c9",
   "metadata": {},
   "source": [
    "# Performance of the KMeans algorithm\n",
    "\n",
    "- Often measured in Accuracy\n",
    "\n",
    "![\"acc.png\"](acc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b8bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# Apply K-means clusteriang\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=42)\n",
    "kmeans.fit(X_train_scaled)\n",
    "y_kmeans = kmeans.predict(X_test_scaled)\n",
    "\n",
    "# Map cluster labels to original labels (0: benign, 1: malignant)\n",
    "mapping = (\n",
    "    {0: 1, 1: 0}\n",
    "    if confusion_matrix(y_test, y_kmeans)[0][0] < confusion_matrix(y_test, y_kmeans)[1][0]\n",
    "    else {0: 0, 1: 1}\n",
    ")\n",
    "y_kmeans_mapped = [mapping[label] for label in y_kmeans]\n",
    "\n",
    "# Evaluate the clustering performance\n",
    "accuracy_Kmeans = accuracy_score(y_test, y_kmeans_mapped)\n",
    "conf_matrix_Kmeans = confusion_matrix(y_test, y_kmeans_mapped)\n",
    "\n",
    "# Print the results\n",
    "print(f\"KMeans Accuracy using {len(data.feature_names)} features: {accuracy_Kmeans * 100:.1f}%\")\n",
    "print(f\"KMeans Confusion Matrix using {len(data.feature_names)} features:\")\n",
    "print(conf_matrix_Kmeans)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb38f73",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Accuracy visualized\n",
    "![\"acc2.png\"](acc2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17abf10c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualize the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd606d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Cluster\"] = y_kmeans_mapped\n",
    "df_test[\"Cluster\"] = df_test[\"Cluster\"].map({i: v for i, v in enumerate(data.target_names)})\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_test, x=\"mean radius\", y=\"mean texture\", hue=\"Cluster\", style=\"Target\", palette=\"viridis\")\n",
    "plt.title(f\"K-means Clustering of Breast Cancer Data using {len(data.feature_names)} features\")\n",
    "plt.xlabel(\"Mean Radius\")\n",
    "plt.ylabel(\"Mean Texture\")\n",
    "plt.legend(title=\"Cluster/Target\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3673fa80",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "- What is the accuracy of KMeans if we use 1 feature?\n",
    "- Use the following code as the starting point\n",
    "- Data should be fitted using the training data, and verified using test data\n",
    "\n",
    "- What will happen to the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ca76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first feature of X, and do KMeans clustering\n",
    "X_train_scaled1 = X_train_scaled[:, :1]  # 1 feature only\n",
    "X_test_scaled1 = X_test_scaled[:, :1]  # 1 feature only\n",
    "# y_test is the label variable, for the test set! the label doesn't change!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9893bf80",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e22f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-means clustering and predict the labels\n",
    "print(\"Applt K-means clustering after this print!!!!\")\n",
    "kmeans.fit(X_train_scaled1)\n",
    "y_kmeans1 = kmeans.predict(X_test_scaled1)\n",
    "\n",
    "\n",
    "# Map cluster labels to original labels (0: benign, 1: malignant)\n",
    "mapping = (\n",
    "    {0: 1, 1: 0}\n",
    "    if confusion_matrix(y_test, y_kmeans1)[0][0] < confusion_matrix(y_test, y_kmeans1)[1][0]\n",
    "    else {0: 0, 1: 1}\n",
    ")\n",
    "y_kmeans1_mapped = [mapping[label] for label in y_kmeans1]\n",
    "\n",
    "# Evaluate the clustering performance\n",
    "print(\"Evaluate the clustering performance\")\n",
    "accuracy_Kmeans1 = accuracy_score(y_test, y_kmeans1_mapped)\n",
    "conf_matrix_Kmeans1 = confusion_matrix(y_test, y_kmeans1_mapped)\n",
    "\n",
    "# Print the results\n",
    "print(f\"KMeans Accuracy using {1} features: {accuracy_Kmeans1 * 100:.1f}%\")\n",
    "print(f\"KMeans Confusion Matrix using {1} features:\")\n",
    "print(conf_matrix_Kmeans1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee42b67",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Supervised Learning\n",
    "\n",
    "**Why Train the Model?**\n",
    "\n",
    "- Training the model involves learning patterns from the training data, which the model uses to make predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982a006f",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors\n",
    "\n",
    "- Lazy Learner\n",
    "- K: How many neighbors, should be considered, to find the closet fit\n",
    "    - Basically, if K = 3, then we find the three closest samples to a given sample, and pick the majority\n",
    "\n",
    "\n",
    "## \n",
    "1. The k-nearest neighbor algorithm is imported from the scikit-learn package.\n",
    "2. Create feature and target variables. \n",
    "3. Split data into training and test data.\n",
    "4. Generate a k-NN model using neighbors value.\n",
    "5. Train or fit the data into the model.\n",
    "6. Predict the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# K Nearest Neighbors\n",
    "\n",
    "![\"knn.png\"](knn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7348e03",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35691977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_knn = knn.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "# Evaluate the clustering performance\n",
    "accuracy_knn = knn.score(X_test_scaled, y_test)\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_knn)\n",
    "\n",
    "# Print the results\n",
    "print(f\"KNN Accuracy using {len(data.feature_names)} features: {accuracy_knn * 100:.1f}%\")\n",
    "print(f\"KNN Confusion Matrix using {len(data.feature_names)} features:\")\n",
    "print(conf_matrix_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4141c193",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "- What is the accuracy of K Nearest Neighbors if we use 1 feature?\n",
    "- Data should be fitted using the training data, and verified using test data\n",
    "\n",
    "- What do you expect will happen to the accuracy\n",
    "- How will the accuracy be compared to KMeans?\n",
    "\n",
    "- Use the following code as the starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667c8bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first feature of X, and do KMeans clustering\n",
    "X_train_scaled1 = X_train_scaled[:, :1]  # 1 feature only\n",
    "X_test_scaled1 = X_test_scaled[:, :1]  # 1 feature only\n",
    "# y_train, y_test are the label variables. the label doesn't change!\n",
    "\n",
    "\n",
    "# Apply KNN  and predict the labels\n",
    "print(\"Applt KNN clustering after this print!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd4b861",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cce03d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply KNN  and predict the labels\n",
    "print(\"Applt KNN clustering after this print!!!!\")\n",
    "knn.fit(X_train_scaled1, y_train)\n",
    "y_knn1 = knn.predict(X_test_scaled1)\n",
    "\n",
    "\n",
    "# Evaluate the clustering performance\n",
    "print(\"Evaluate the clustering performance\")\n",
    "accuracy_knn1 = knn.score(X_test_scaled1, y_test)\n",
    "conf_matrix_knn1 = confusion_matrix(y_test, y_knn1)\n",
    "\n",
    "# Print the results\n",
    "print(f\"KNN Accuracy using {1} features: {accuracy_knn1 * 100:.1f}%\")\n",
    "print(f\"KNN Confusion Matrix using {1} features:\")\n",
    "print(conf_matrix_knn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997b50c6",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM's)\n",
    "\n",
    "Support Vector Machine tries to find the best separating line between classes.\n",
    "\n",
    "**The advantages of support vector machines are:**\n",
    "- Effective in high dimensional spaces.\n",
    "- Still effective in cases where number of dimensions is greater than the number of samples.\n",
    "- Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient.\n",
    "- Versatile: different Kernel functions can be specified for the decision function. \n",
    "\n",
    "**The disadvantages of support vector machines include:**\n",
    "- If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial.\n",
    "- SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below).\n",
    "\n",
    "\n",
    "## How SVM Works\n",
    "- SVM finds the best hyperplane that separates the data into different classes while maximizing the margin.\n",
    "\n",
    "![\"svm.png\"](svm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1e418f",
   "metadata": {},
   "source": [
    "# Example using Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc08f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_clf = clf.predict(X_test)\n",
    "accuracy_clf = accuracy_score(y_test,y_clf)\n",
    "conf_matrix_clf = confusion_matrix(y_test,y_clf)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(f\"SVM Accuracy using {len(data.feature_names)} features: {accuracy_knn1 * 100:.1f}%\")\n",
    "print(f\"SVM Confusion Matrix using {len(data.feature_names)} features:\")\n",
    "print(conf_matrix_knn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c9d4b3",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Improving the Model\n",
    "\n",
    "**Why Improve the Model?**\n",
    "- Improving the model can lead to better performance and more accurate predictions.\n",
    "- Experiment with different models, hyperparameters, and feature engineering to improve performance.\n",
    "\n",
    "**Examples:**\n",
    "- Hyperparameter Tuning: Adjusting parameters like max_depth for Decision Trees.\n",
    "- Feature Engineering: Creating new features from existing data.\n",
    "\n",
    "- You will not be doing this, this is far beond this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b073b6",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "\n",
    "## Exercise 1 - Classification with Breast Cancer Dataset\n",
    "\n",
    "**Objective**: Train a classifier on the Breast Cancer dataset and evaluate its performance.\n",
    "Steps:\n",
    "1. Load the Breast Cancer dataset.\n",
    "2. Split the data into training and testing sets.\n",
    "3. Train a Decision Tree classifier using one feature.\n",
    "4. Train a Decision Tree classifier using multiple features.\n",
    "5. Make predictions and evaluate accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365e44bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load data\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model with one feature\n",
    "X_train_one_feature = X_train[:, [0]]  # Using 'mean radius'\n",
    "X_test_one_feature = X_test[:, [0]]\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_one_feature, y_train)\n",
    "\n",
    "# Make predictions with one feature\n",
    "y_pred_one_feature = model.predict(X_test_one_feature)\n",
    "\n",
    "# Evaluate model with one feature\n",
    "accuracy_one_feature = accuracy_score(y_test, y_pred_one_feature)\n",
    "print(f\"Accuracy with one feature: {accuracy_one_feature}\")\n",
    "\n",
    "# Train model with multiple features\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with multiple features\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model with multiple features\n",
    "accuracy_Kmeans = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with multiple features: {accuracy_Kmeans}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da1bd23",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
